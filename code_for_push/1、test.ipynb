{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 打开对应的数据集\n",
    "# 先做出来，在封装吧。\n",
    "# def load_data(path):\n",
    "temp_path = \"./global/temp.npy\"\n",
    "wind_path = \"./global/wind.npy\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "temp_array = np.load(temp_path)\n",
    "wind_array = np.load(wind_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtemp_array\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m wind_array\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m temp_array\n",
      "\u001B[1;31mNameError\u001B[0m: name 'temp_array' is not defined"
     ]
    }
   ],
   "source": [
    "# temp_array\n",
    "# del wind_array\n",
    "# del temp_array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(17544, 3850, 1)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_array.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(17544, 3850)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_array.squeeze().shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(67544400, 1)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp_array[:,:,0].shape\n",
    "temp_array.reshape(-1,1).shape          # 所以，本章的数据处理就是这样的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3850, 17544)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 站点数目\n",
    "num_sites = temp_array.shape[1]\n",
    "# 时间数目\n",
    "num_time_steps = temp_array.shape[0]\n",
    "num_sites,num_time_steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# LSTM模型喜欢的数据格式。\n",
    "# temp_input = temp_array.reshape(-1, num_sites, 1)\n",
    "# wind_input = wind_array.reshape(-1, num_sites, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ------- 加载数据 ---------#\n",
    "## 导包"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "global_data = np.load('./global/global_data.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(5848, 4, 9, 3850)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看对应数据的维度\n",
    "global_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(5848, 4, 9)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对数据进行切片\n",
    "slice_gdata = global_data[:,:,:,1]\n",
    "slice_gdata.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(5848, 4, 9)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pd_gdata \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mslice_gdata\u001B[49m\u001B[43m)\u001B[49m       \u001B[38;5;66;03m# 还可以指定对应的列名\u001B[39;00m\n\u001B[0;32m      2\u001B[0m pd_gdata\n",
      "File \u001B[1;32mD:\\new_conda\\lib\\site-packages\\pandas\\core\\frame.py:694\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    684\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m dict_to_mgr(\n\u001B[0;32m    685\u001B[0m             \u001B[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001B[39;00m\n\u001B[0;32m    686\u001B[0m             \u001B[38;5;66;03m# attribute \"name\"\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    691\u001B[0m             typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    692\u001B[0m         )\n\u001B[0;32m    693\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 694\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m \u001B[43mndarray_to_mgr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    699\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001B[39;00m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(data):\n",
      "File \u001B[1;32mD:\\new_conda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:331\u001B[0m, in \u001B[0;36mndarray_to_mgr\u001B[1;34m(values, index, columns, dtype, copy, typ)\u001B[0m\n\u001B[0;32m    326\u001B[0m         values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;66;03m# by definition an array here\u001B[39;00m\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;66;03m# the dtypes will be coerced to a single dtype\u001B[39;00m\n\u001B[1;32m--> 331\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_prep_ndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy_on_sanitize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dtype_equal(values\u001B[38;5;241m.\u001B[39mdtype, dtype):\n\u001B[0;32m    334\u001B[0m     shape \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32mD:\\new_conda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:591\u001B[0m, in \u001B[0;36m_prep_ndarray\u001B[1;34m(values, copy)\u001B[0m\n\u001B[0;32m    589\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape((values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    590\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m values\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m--> 591\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust pass 2-d input. shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    593\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m values\n",
      "\u001B[1;31mValueError\u001B[0m: Must pass 2-d input. shape=(5848, 4, 9)"
     ]
    }
   ],
   "source": [
    "# pd_gdata = pd.DataFrame(slice_gdata)       # 还可以指定对应的列名\n",
    "# pd_gdata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5848, 4, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([4, 9])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_gdata = torch.tensor(slice_gdata)       # 还可以指定对应的列名\n",
    "# torch_gdata.item()              # 这个是只有一个数时才能使用，一个张量中含有多个值时不能直接打印\n",
    "print(torch_gdata.shape)\n",
    "torch_gdata[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 先随便找个模型进行数据的拟合了\n",
    "### 根据拟合的精度，反过来再看维度的选择"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_encoder_layers, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=num_heads,batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.positional_encoding = self._generate_positional_encoding(input_dim)\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.positional_encoding[:x.size(0), :]     #\n",
    "        x = self.transformer_encoder(x)\n",
    "        out = self.fc(x[:, -1, :])  # 取序列的最后一个时间点作为输出\n",
    "        return out.view(-1,1)\n",
    "\n",
    "    def _generate_positional_encoding(self, dim, max_len=4):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "17544"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5848*3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "temp_data = torch.rand((17544,3850,1))\n",
    "wind_data = torch.rand((17544,3850,1))\n",
    "global_data = torch.rand((5848,4,9,3850))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17544, 3850])\n",
      "torch.Size([1, 17544, 3850])\n",
      "torch.Size([1, 5848, 138600])\n"
     ]
    }
   ],
   "source": [
    "print(temp_data.squeeze(-1).unsqueeze(axis=0).shape)\n",
    "print(wind_data.squeeze(-1).unsqueeze(axis=0).shape)\n",
    "print(global_data.reshape(-1, 3850 * 4 * 9).unsqueeze(0).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "# temp_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([35088, 3850])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拼接两个数据\n",
    "wt_data = torch.cat((temp_data,wind_data)).squeeze(-1)  # 压缩最后一个维度\n",
    "wt_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([210528, 3850])"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global_data.view(-1,3850).shape\n",
    "global_data_reshaped = global_data.view(-1,3850)\n",
    "global_data_reshaped.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([245616, 3850])"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用cat方法除了拼接的维度，其他维度都是要相同的\n",
    "data = torch.cat((wt_data,global_data_reshaped),dim=0)          # 除了融合的维度以外其他维度都需要相同才行\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 其他拼接张量的方法\n",
    "- 调用torch.utils.data.TensorDataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35088, 3850])\n",
      "torch.Size([210528, 3850])\n"
     ]
    }
   ],
   "source": [
    "print(wt_data.shape)\n",
    "print(global_data.view(-1,3850).shape)\n",
    "# TensorDataSet默认是按\n",
    "dataset_train = TensorDataset(wt_data.permute(1,0),global_data.view(-1,3850).permute(1,0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
